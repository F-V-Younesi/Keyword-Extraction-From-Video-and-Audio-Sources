{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovRrAGLISPyO"
      },
      "source": [
        "# **بسم الله الرحمن الرحیم**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wcf2NfTtcBpI"
      },
      "source": [
        "###The first mode of input: Upload Your video/Audio file here:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMHLLAvPed-4"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "# path = next(iter(uploaded))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3X6bVVnjI5w"
      },
      "source": [
        "### Or place a .csv file that contains a column for video|audio path and a column for caption text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlrJZAUNjImA"
      },
      "outputs": [],
      "source": [
        "# csv_path='data.csv'\n",
        "# csv=pd.read_csv(csv_path)\n",
        "# path=csv['video_path'][0]\n",
        "# caption=csv['caption'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q69jJ798dOGo",
        "outputId": "90756e60-03ae-4945-9b82-13906c39b469"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emH4nSLLdO9l"
      },
      "source": [
        "#Get Input | Format Recognition | Converting Video to Audio | Removing Music:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swuovnkoeRNw"
      },
      "source": [
        "## Get Input | Format Recognition | Converting Video to Audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0hLe2qfINolG"
      },
      "outputs": [],
      "source": [
        "# Importing Libraries:\n",
        "import moviepy.editor\n",
        "import os\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqXvakcAdZNp"
      },
      "outputs": [],
      "source": [
        "# This section of code, Investigate that the input file is audio or video or None of them.\n",
        "audio_suffixes = (\"mp3\", \"wav\",\"3gp\",'8svx','aa','aac','aax','act','aiff','alac','amr','ape','au','awb','cda','dss','dvf','flac','gsm','iklax','ivs','m4a','m4b','m4p','mmf','movpkg','mpc','msv','nmf','ogg','oga','mogg','opus','rm','ra','raw','rf64','sln','tta','voc','vox','webm','wma','wv')\n",
        "video_suffixes =('webm','mkv','mp4','m4p','m4v','flv','vob','ogv','drc','gif','gifv','mng','avi','MTS','M2TS','TS','mov','qt','wmv','yuv','rmvb','viv','asf','amv','rm','ogg','sv','3pg','3g2','mxf','roq','nsv','f4v','f4p','f4a','f4b')\n",
        "def is_video(path):\n",
        "  if path.endswith(video_suffixes):\n",
        "    print(\"The input is a video file.\")\n",
        "    return True\n",
        "  elif path.endswith(audio_suffixes):\n",
        "    print(\"The input is an audio file.\")\n",
        "    return False\n",
        "  else:\n",
        "    print(\"This file has neither video nor audio format. Please enter a file with correct format.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IntijCZXZN_k"
      },
      "outputs": [],
      "source": [
        "#Convertion of video to audio:\n",
        "def vid2audio(path):\n",
        "  #Load the Video\n",
        "  video = moviepy.editor.VideoFileClip(path)\n",
        "\n",
        "  #Extract the Audio\n",
        "  audio = video.audio\n",
        "\n",
        "  #Export the Audio\n",
        "  audio.write_audiofile(\"Audio.mp3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33Plnak4c0mD",
        "outputId": "1bf4fc83-7ce3-4e96-9553-abdd8352e5aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The input is a video file.\n",
            "MoviePy - Writing audio in Audio.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                     "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "path='/content/414669282_856731373122399_1711351064169457727_n.mp4'\n",
        "video=is_video(path)\n",
        "if video is True:\n",
        "  vid2audio(path)\n",
        "  path=\"Audio.mp3\"\n",
        "elif video is False:\n",
        "  os.rename(path,'Audio.mp3')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Km_0bZpSFjO0"
      },
      "source": [
        "##Recognize & remove music:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJbB2NwpF2qN",
        "outputId": "3f38a0be-2aac-42d1-e0ff-0ece48d6bd06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pydub\n",
        "from pydub import AudioSegment, silence\n",
        "import io\n",
        "from pathlib import Path\n",
        "import select\n",
        "from shutil import rmtree\n",
        "import subprocess as sp\n",
        "import sys\n",
        "from typing import Dict, Tuple, Optional, IO\n",
        "\n",
        "# This function checks that if a audio file exists for music separation or not. if exists, saves the file path:\n",
        "def find_files(in_path):\n",
        "    out = []\n",
        "    for file in Path(in_path).iterdir():\n",
        "        if file.suffix.lower().lstrip(\".\") in extensions:\n",
        "            out.append(file)\n",
        "    return out\n",
        "\n",
        "# This function is used for printing subprocesses:\n",
        "def copy_process_streams(process: sp.Popen):\n",
        "    def raw(stream: Optional[IO[bytes]]) -> IO[bytes]:\n",
        "        assert stream is not None\n",
        "        if isinstance(stream, io.BufferedIOBase):\n",
        "            stream = stream.raw\n",
        "        return stream\n",
        "\n",
        "    p_stdout, p_stderr = raw(process.stdout), raw(process.stderr)\n",
        "    stream_by_fd: Dict[int, Tuple[IO[bytes], io.StringIO, IO[str]]] = {\n",
        "        p_stdout.fileno(): (p_stdout, sys.stdout),\n",
        "        p_stderr.fileno(): (p_stderr, sys.stderr),\n",
        "    }\n",
        "    fds = list(stream_by_fd.keys())\n",
        "\n",
        "    while fds:\n",
        "        # `select` syscall will wait until one of the file descriptors has content.\n",
        "        ready, _, _ = select.select(fds, [], [])\n",
        "        for fd in ready:\n",
        "            p_stream, std = stream_by_fd[fd]\n",
        "            raw_buf = p_stream.read(2 ** 16)\n",
        "            if not raw_buf:\n",
        "                fds.remove(fd)\n",
        "                continue\n",
        "            buf = raw_buf.decode()\n",
        "            std.write(buf)\n",
        "            std.flush()\n",
        "\n",
        "# This function seperate music from audio file. the outputs are vocal file and three music files:\n",
        "def separate(inp=None, outp=None):\n",
        "    inp = inp or in_path\n",
        "    outp = outp or out_path\n",
        "    cmd = [\"python3\", \"-m\", \"demucs.separate\", \"-o\", str(outp), \"-n\", model]\n",
        "    if mp3:\n",
        "        cmd += [\"--mp3\", f\"--mp3-bitrate={mp3_rate}\"]\n",
        "\n",
        "    files = [str(f) for f in find_files(inp)]\n",
        "    if not files:\n",
        "        print(f\"No valid audio files in {in_path}\")\n",
        "        return\n",
        "    print(\"**Going to separate Music and Vocals from the files:\\n\")\n",
        "    p = sp.Popen(cmd + files, stdout=sp.PIPE, stderr=sp.PIPE)\n",
        "    copy_process_streams(p)\n",
        "    p.wait()\n",
        "    if p.returncode != 0:\n",
        "        print(\"Command failed, something went wrong.\")\n",
        "\n",
        "# This function calls \"seperate\" function and saves vocal file and three music files:\n",
        "def remove_music():\n",
        "    out_path = Path('separated')\n",
        "    in_path = Path('tmp_in')\n",
        "\n",
        "    if in_path.exists():\n",
        "        rmtree(in_path)\n",
        "    in_path.mkdir()\n",
        "\n",
        "    if out_path.exists():\n",
        "        rmtree(out_path)\n",
        "    out_path.mkdir()\n",
        "\n",
        "    # name='Audio.mp3'\n",
        "    !cp '/content/Audio.mp3' '/content/tmp_in'\n",
        "    separate(in_path, out_path)\n",
        "\n",
        "# This function finds length of music in audio file:\n",
        "def music_length(overlay_music):\n",
        "    silence1 = silence.detect_silence(overlay_music, min_silence_len=3000, silence_thresh=-40)\n",
        "    silencelist = [((start/1000),(stop/1000)) for start,stop in silence1] #convert to sec\n",
        "    c=0\n",
        "    for i in range(0,len(silencelist)):\n",
        "      c=c+silencelist[i][1]-silencelist[i][0]\n",
        "    T=len(overlay_music)\n",
        "    music_len=(T-c)/(T)\n",
        "    return music_len\n",
        "\n",
        "# This function finds audio content usability mode:\n",
        "def music_mode(overlay_music,vocal):\n",
        "  vocal_loudness=vocal.dBFS\n",
        "  loudness=overlay_music.dBFS\n",
        "  if loudness<-40:\n",
        "    print('\\n **This Video/Audio does not contain Music contents.')\n",
        "    useful_content=True\n",
        "    return useful_content\n",
        "\n",
        "  elif loudness<-30:\n",
        "    print('\\n **This Video/Audio contain background music on main contents that can influence on accuracy of results.')\n",
        "    useful_content=True\n",
        "    return useful_content\n",
        "\n",
        "  elif loudness>-18:\n",
        "    if vocal_loudness<-30:\n",
        "        print(\"\\n **This Video/Audio contains Only Music and does not contain any useful contents.\")\n",
        "        useful_content=False\n",
        "        return useful_content\n",
        "    else:\n",
        "        print(\"\\n **This Video/Audio contains Music & singer's voice and does not contain any useful contents.\")\n",
        "        useful_content=False\n",
        "        return useful_content\n",
        "\n",
        "  else:\n",
        "    if music_length(overlay_music)<0.95:\n",
        "      print('\\n **This Video/Audio contain background music on main contents that can influence on accuracy of results.')\n",
        "      useful_content=True\n",
        "      return useful_content\n",
        "    else:\n",
        "      print(\"\\n **This Video/Audio contains Music & singer's voice and does not contain any useful content for key extraction.\")\n",
        "      useful_content=False\n",
        "      return useful_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZALwYagFFwPv",
        "outputId": "13ff4cc2-49ce-41e0-e505-7f14b9a84efb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Start of the operation to check the presence of music in the audio file:\n",
            "\n",
            "Collecting demucs\n",
            "  Cloning https://github.com/facebookresearch/demucs to /tmp/pip-install-n4_z_c8e/demucs_e08e2e61824f40ee950dd13a6b964ccf\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/demucs /tmp/pip-install-n4_z_c8e/demucs_e08e2e61824f40ee950dd13a6b964ccf\n",
            "  Resolved https://github.com/facebookresearch/demucs to commit e976d93ecc3865e5757426930257e200846a520a\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting dora-search (from demucs)\n",
            "  Downloading dora_search-0.1.12.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.1/87.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting einops (from demucs)\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting julius>=0.2.3 (from demucs)\n",
            "  Downloading julius-0.2.7.tar.gz (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting lameenc>=1.2 (from demucs)\n",
            "  Downloading lameenc-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (239 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.8/239.8 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openunmix (from demucs)\n",
            "  Downloading openunmix-1.2.1-py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.7/46.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from demucs) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from demucs) (2.1.0+cu121)\n",
            "Collecting torchaudio<2.1,>=0.8 (from demucs)\n",
            "  Downloading torchaudio-2.0.2-cp310-cp310-manylinux1_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from demucs) (4.66.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->demucs) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->demucs) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->demucs) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->demucs) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->demucs) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->demucs) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->demucs) (2.1.0)\n",
            "Collecting torch>=1.8.1 (from demucs)\n",
            "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch>=1.8.1->demucs)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch>=1.8.1->demucs)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch>=1.8.1->demucs)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m105.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch>=1.8.1->demucs)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch>=1.8.1->demucs)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch>=1.8.1->demucs)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch>=1.8.1->demucs)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch>=1.8.1->demucs)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch>=1.8.1->demucs)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch>=1.8.1->demucs)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch>=1.8.1->demucs)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==2.0.0 (from torch>=1.8.1->demucs)\n",
            "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.8.1->demucs) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.8.1->demucs) (0.42.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->demucs) (3.27.9)\n",
            "Collecting lit (from triton==2.0.0->torch>=1.8.1->demucs)\n",
            "  Downloading lit-17.0.6.tar.gz (153 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting omegaconf (from dora-search->demucs)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting retrying (from dora-search->demucs)\n",
            "  Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
            "Collecting submitit (from dora-search->demucs)\n",
            "  Downloading submitit-1.5.1-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.7/74.7 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting treetable (from dora-search->demucs)\n",
            "  Downloading treetable-0.2.5.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openunmix->demucs) (1.25.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->demucs) (2.1.5)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf->dora-search->demucs)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from retrying->dora-search->demucs) (1.16.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from submitit->dora-search->demucs) (2.2.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->demucs) (1.3.0)\n",
            "Building wheels for collected packages: demucs, julius, dora-search, antlr4-python3-runtime, treetable, lit\n",
            "  Building wheel for demucs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for demucs: filename=demucs-4.1.0a2-py3-none-any.whl size=83543 sha256=782b462f00e94beea55b583f47fae7abb4fe015cc0cc2aa0a589adfd93aa91b6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-o9ysm_nh/wheels/45/e4/ca/7791f04b554e5433713e22900eaf11595e27c454fb65ac30ab\n",
            "  Building wheel for julius (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for julius: filename=julius-0.2.7-py3-none-any.whl size=21870 sha256=ad8d26c7b8bfebe7dadc6f8def4f8dd0b12ccef9c28cbc5a47c5e7a0882ae89c\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/b2/05/f883527ffcb7f2ead5438a2c23439aa0c881eaa9a4c80256f4\n",
            "  Building wheel for dora-search (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dora-search: filename=dora_search-0.1.12-py3-none-any.whl size=75092 sha256=57939b6a07751498217ad234cd3c5645d8b8f3267cdc2384c6ee52ed67ebc033\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/c2/c0/bea5cc405497284d584b958f293ef32c23bad42ae5e44d973c\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=00ff01410f451a3d7c1ae1af63e225f8f85c95ec1628743aa76e39e84bbd8423\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "  Building wheel for treetable (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for treetable: filename=treetable-0.2.5-py3-none-any.whl size=7333 sha256=23c168b386c461f787a20c541b450610e48ef948b4fc9c86b24035007d5ffca2\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/55/0e/91c3655bdb162446f8a7cd477579397544454a63ae7c599c0c\n",
            "  Building wheel for lit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lit: filename=lit-17.0.6-py3-none-any.whl size=93255 sha256=e5a8fcd579ead99c235a51c63a00354814a26129f7b8bf946476a678eb4019e2\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/dd/04/47d42976a6a86dc2ab66d7518621ae96f43452c8841d74758a\n",
            "Successfully built demucs julius dora-search antlr4-python3-runtime treetable lit\n",
            "Installing collected packages: lit, lameenc, antlr4-python3-runtime, treetable, submitit, retrying, omegaconf, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, einops, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, torchaudio, openunmix, julius, dora-search, demucs\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.1.0\n",
            "    Uninstalling triton-2.1.0:\n",
            "      Successfully uninstalled triton-2.1.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.0+cu121\n",
            "    Uninstalling torch-2.1.0+cu121:\n",
            "      Successfully uninstalled torch-2.1.0+cu121\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.1.0+cu121\n",
            "    Uninstalling torchaudio-2.1.0+cu121:\n",
            "      Successfully uninstalled torchaudio-2.1.0+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchvision 0.16.0+cu121 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed antlr4-python3-runtime-4.9.3 demucs-4.1.0a2 dora-search-0.1.12 einops-0.7.0 julius-0.2.7 lameenc-1.7.0 lit-17.0.6 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 omegaconf-2.3.0 openunmix-1.2.1 retrying-1.3.4 submitit-1.5.1 torch-2.0.1 torchaudio-2.0.2 treetable-0.2.5 triton-2.0.0\n",
            "**Going to separate Music and Vocals from the files:\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://dl.fbaipublicfiles.com/demucs/hybrid_transformer/955717e8-8726e21a.th\" to /root/.cache/torch/hub/checkpoints/955717e8-8726e21a.th\n",
            "100%|██████████| 80.2M/80.2M [00:01<00:00, 49.0MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected model is a bag of 1 models. You will see that many progress bars per track.\n",
            "Separated tracks will be stored in /content/separated/htdemucs\n",
            "Separating track tmp_in/Audio.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|████████████████████████████████████████████████| 70.19999999999999/70.19999999999999 [00:09<00:00,  7.64seconds/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: separated/ (stored 0%)\n",
            "  adding: separated/htdemucs/ (stored 0%)\n",
            "  adding: separated/htdemucs/Audio/ (stored 0%)\n",
            "  adding: separated/htdemucs/Audio/vocals.mp3 (deflated 2%)\n",
            "  adding: separated/htdemucs/Audio/drums.mp3 (deflated 1%)\n",
            "  adding: separated/htdemucs/Audio/bass.mp3 (deflated 1%)\n",
            "  adding: separated/htdemucs/Audio/other.mp3 (deflated 4%)\n",
            "\n",
            " **This Video/Audio contain background music on main contents that can influence on accuracy of results.\n"
          ]
        }
      ],
      "source": [
        "if os.path.exists('Audio.mp3'):\n",
        "  print('**Start of the operation to check the presence of music in the audio file:\\n')\n",
        "  !python3 -m pip install -U git+https://github.com/facebookresearch/demucs#egg=demucs\n",
        "\n",
        "\n",
        "  model = \"htdemucs\"\n",
        "  extensions = [\"mp3\", \"wav\", \"ogg\", \"flac\"]  # those file types supported in this model.\n",
        "  two_stems = None   # only separate one stems from the rest, for instance\n",
        "\n",
        "  # Options for the output audio:\n",
        "  mp3 = True\n",
        "  mp3_rate = 320\n",
        "  in_path = '/content/demucs'\n",
        "  out_path = '/content/demucs_separated/'\n",
        "\n",
        "  remove_music()\n",
        "  !zip -r separated.zip separated\n",
        "\n",
        "  music1=AudioSegment.from_mp3('/content/separated/htdemucs/Audio/bass.mp3')\n",
        "  music2=AudioSegment.from_mp3('/content/separated/htdemucs/Audio/drums.mp3')\n",
        "  music3=AudioSegment.from_mp3('/content/separated/htdemucs/Audio/other.mp3')\n",
        "  vocal=AudioSegment.from_mp3('/content/separated/htdemucs/Audio/vocals.mp3')\n",
        "\n",
        "  overlay_music = music1.overlay(music2, position=0).overlay(music3, position=0)\n",
        "  useful_content=music_mode(overlay_music,vocal)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSTAGj4TdiEg"
      },
      "source": [
        "#STT(Speech To Text):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOurxYbqqdhN"
      },
      "source": [
        "##Merged Whisper(Large and Medium models):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "avBpJ3MQogKd"
      },
      "outputs": [],
      "source": [
        "# This function convert STT result as \"List\" of phrases to \"String\":\n",
        "def list2str(main_content):\n",
        "  main_content_str=''\n",
        "  for i in range (0,len(main_content)):\n",
        "    main_content_str=main_content_str+'،'+main_content[i]\n",
        "  return main_content_str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yp_upnFBThgf"
      },
      "outputs": [],
      "source": [
        "# This function finds end of time periods of every segments:\n",
        "def find_end_segments(segments,segmentsl):\n",
        "  listend=[]\n",
        "  listendl=[]\n",
        "  for segment in segments:\n",
        "    listend.append(segment['end'])\n",
        "\n",
        "  for segment in segmentsl:\n",
        "    listendl.append(segment['end'])\n",
        "  return listend,listendl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KvbfZ9wiWCKr"
      },
      "outputs": [],
      "source": [
        "# This function Finds common endings in time periods of segments.\n",
        "def common_endings(list1,list2):\n",
        "  listcommon1=[]\n",
        "  listcommon2=[]\n",
        "  if len(list1)<len(list2):\n",
        "    slist=list1\n",
        "    dlist=list2\n",
        "  else:\n",
        "    slist=list2\n",
        "    dlist=list1\n",
        "\n",
        "  for i in range(0, len(slist)):\n",
        "    d=[]\n",
        "    for j in range(0,len(dlist)):\n",
        "        d.append(abs(slist[i]-dlist[j]))\n",
        "    if min(d)<5:\n",
        "      listcommon2.append(dlist[d.index(min(d))])\n",
        "      listcommon1.append(slist[i])\n",
        "\n",
        "  if slist==list1:\n",
        "    return listcommon1,listcommon2\n",
        "  else:\n",
        "    return listcommon2,listcommon1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9HXeUwmVgLLh"
      },
      "outputs": [],
      "source": [
        "#This function finds best prediction between common time periods for medium and large model:\n",
        "def best_prediction(segments,segmentsl,listcommon1,listcommon2):\n",
        "  listtxt=[]\n",
        "  previous_id=-1\n",
        "  previous_id2=-1\n",
        "\n",
        "  for j in range(0,len(listcommon1)):\n",
        "    id=0\n",
        "    while segments[id]['end']!=listcommon1[j]:\n",
        "      id=id+1\n",
        "    id2=0\n",
        "    while segmentsl[id2]['end']!=listcommon2[j]:\n",
        "      id2=id2+1\n",
        "\n",
        "    txt1=''\n",
        "    txt2=''\n",
        "    for i in range(previous_id+1,id+1):\n",
        "      txt1=txt1+segments[i]['text']\n",
        "    for i in range(previous_id2+1,id2+1):\n",
        "      txt2=txt2+segmentsl[i]['text']\n",
        "    if len(txt1)>len(txt2):\n",
        "      listtxt.append(txt1)\n",
        "    else:\n",
        "      listtxt.append(txt2)\n",
        "    previous_id=id\n",
        "    previous_id2=id2\n",
        "\n",
        "  return listtxt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_KnsJ1pJ9Or"
      },
      "outputs": [],
      "source": [
        "# This function Integrates best prediction for all time sections:\n",
        "def Integrated_stt(result,resultl):\n",
        "  segments = result['segments']\n",
        "  segmentsl=resultl['segments']\n",
        "  listend,listendl = find_end_segments(segments,segmentsl)\n",
        "\n",
        "  listcommon1,listcommon2 = common_endings(listend,listendl)\n",
        "\n",
        "  main_content = best_prediction(segments,segmentsl,listcommon1,listcommon2)\n",
        "  return main_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKYFjeD_rWxl",
        "outputId": "8121d6a3-f0b8-46f8-cfcb-5c2edfd0ccb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-zcdc5vxd\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-zcdc5vxd\n",
            "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (1.25.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (4.66.2)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.1.0)\n",
            "Collecting tiktoken (from openai-whisper==20231117)\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.27.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.13.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (17.0.6)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (11.7.91)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->openai-whisper==20231117) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->openai-whisper==20231117) (0.42.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=802825 sha256=8129d01d86ae606bd6af18420bdea78630f5d24b98aeb695d44a437424298c8b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-zrwjca4u/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: tiktoken, openai-whisper\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-whisper-20231117 tiktoken-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git\n",
        "import whisper\n",
        "\n",
        "# This function detect language that is spoken in audio file:\n",
        "def detect_lang(vocal_path):\n",
        "  model = whisper.load_model(\"base\")\n",
        "\n",
        "  # load audio and trim it to fit 30 seconds\n",
        "  audio = whisper.load_audio(vocal_path)\n",
        "  audio = whisper.pad_or_trim(audio)\n",
        "\n",
        "  # make log-Mel spectrogram and move to the same device as the model\n",
        "  mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "\n",
        "  # detect the spoken language\n",
        "  _, probs = model.detect_language(mel)\n",
        "  lang=max(probs, key=probs.get)\n",
        "  print(f\"Detected language: {lang}\")\n",
        "  return lang"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9u1RbdvcXd5",
        "outputId": "73b00744-fdb7-4a5c-a0c1-b56261c4a557"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 139M/139M [00:03<00:00, 46.9MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected language: fa\n",
            "**Start of the STT operation:\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████| 1.42G/1.42G [00:15<00:00, 99.0MiB/s]\n",
            "100%|█████████████████████████████████████| 2.88G/2.88G [00:48<00:00, 64.1MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting parsivar\n",
            "  Downloading parsivar-0.2.3.1-py3-none-any.whl (18.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from parsivar) (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.6.6->parsivar) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.6.6->parsivar) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.6.6->parsivar) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.6.6->parsivar) (4.66.2)\n",
            "Installing collected packages: parsivar\n",
            "Successfully installed parsivar-0.2.3.1\n",
            "This is the main content of Input video/Audio:\n",
            " ،‌شده‌اینها اختلاس و دو زدی محفنن ؟ به این میان شب‌ها دوز‌بود و نمیدونم . او نا دو زدی می‌کردند ، تا هم جدی تن 3 معیار و 370 میلیون دلار ، باید میان رژیم‌ها دو زدی ، این شاه اشتباهی‌بود که این دو سال نرفت آخوندی در ، شب‌ها اگر در سال رفته‌بود سوی قوم در دیده‌بود ، ، حسابی بلد‌بود چه کار ، خلبانی بلد‌بود ، زبان فرانسوی بلد‌بود ، زبان انگلیسی بلد‌بود سیاست بلد‌بود ، ولی این بعد نمی‌کنند ، که بعد این آخوندی کلا سرش هستند ، اگر دو زدی که این طوری دو زدی می‌کنند . اگر بکشد این طوری می‌کنند . به اینکه ضد و روند . ، ناراحت شد ، ناراحتی کردن ، به آخر آمریکا و فرانسه و همه دست به دست هم دیگر دادن ، گفت این ماه دیگر الان دارد زبان می‌کشد ، برای این و خطیلشون می‌کنند . ، پایه که تمام باشند . ، و تمام باشند که ، یک دهم این آخوندها ، افراد و ملت خود شون نکند ، آخوندها روی همه را سفید کردن از علمی که خودشان به وجود آوردن . روی سران و نمود و هیتلر و همه را سفید کردن . ، می‌کنین یزید بد‌بود . ، حالا آخوندها که از یزید به شدن .\n"
          ]
        }
      ],
      "source": [
        "vocal_path='/content/separated/htdemucs/Audio/vocals.mp3'\n",
        "if os.path.exists(vocal_path):\n",
        "  if useful_content:\n",
        "    language=detect_lang(vocal_path)\n",
        "    if language=='fa':\n",
        "      print('**Start of the STT operation:\\n')\n",
        "\n",
        "      model = whisper.load_model(\"medium\")\n",
        "      result = model.transcribe(vocal_path)\n",
        "      modell = whisper.load_model(\"large\")\n",
        "      resultl = modell.transcribe(vocal_path)\n",
        "      main_content=Integrated_stt(result,resultl)\n",
        "\n",
        "      !pip install parsivar\n",
        "      from parsivar import SpellCheck\n",
        "      !mkdir '/usr/local/lib/python3.10/dist-packages/parsivar/resource/spell'\n",
        "      !cp '/content/drive/MyDrive/colab_env/lib/python3.10/site-packages/parsivar/resource/spell/onegram.pckl' '/usr/local/lib/python3.10/dist-packages/parsivar/resource/spell'\n",
        "      !cp '/content/drive/MyDrive/colab_env/lib/python3.10/site-packages/parsivar/resource/spell/mybigram_lm.pckl' '/usr/local/lib/python3.10/dist-packages/parsivar/resource/spell'\n",
        "      checker=SpellCheck()\n",
        "      corrected_text=checker.spell_corrector(list2str(main_content))\n",
        "      print('This is the main content of Input video/Audio:\\n',corrected_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frLB8kOkG5Ny"
      },
      "source": [
        "#Keyword Extraction:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OgBEvT6bHt3"
      },
      "source": [
        "##PERKE KEYWORD EXTRACTOR:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEqXzrh-syhO"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "# This function modifies caption text and prepare it for key extraction:\n",
        "def pure_caption(caption):\n",
        "  #removing Imojis:\n",
        "  emoji_pattern = re.compile(\"[\"\n",
        "          u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "          u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "          u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "          u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                            \"]+\", flags=re.UNICODE)\n",
        "  without_emoji=emoji_pattern.sub(r'',caption)\n",
        "\n",
        "  #Removing IDs:\n",
        "  without_id = re.sub('@[^\\s]+','',without_emoji)\n",
        "\n",
        "  #Finding Hashtags in caption of post:\n",
        "  tags=[]\n",
        "  for tag in without_id.split():\n",
        "    if tag.startswith(\"#\"):\n",
        "      tags.append(tag.strip(\"#\").replace(\"_\", \" \"))\n",
        "\n",
        "  #Removing # sign and _:\n",
        "  without_tag=without_id.replace('#','').replace(\"_\", \" \")\n",
        "\n",
        "  return tags, without_tag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmpBwY2ID0OP"
      },
      "outputs": [],
      "source": [
        "caption='صفحه ای ازکتاب سقوط بهشت داستان زندگی شاه ایران درخور آمدن در شاهنامه بود اثر حماسی فردوسی که راوی طلوع و افول سلسله های پادشاهی ایران در گذر قرنهاست پس از رسیدن به تخت طاووس در سال 1320 زمانی که تازه دوره نوجوانی را پشت سر گذاشته بود محمدرضا شاه پهلوی تهدیدهای نابود کننده ای را از سر گذراند که مردان ضعیف تر را در هم میشکست تجاوز به ایران و اشغال کشور در دوران جنگ خراب کاری کمونیستها سقوط هواپیما چند سوء قصد به جان طرح های کودتا دسیسه های مربوط به خاندان سلطنتی شورشهای مذهبی بحرانهای مربوط به قانون اساسی حتی ترک وطن برای مدتی کوتاه در دورانی که دیگر پادشاهان و ملکه ها از تخت به زیر کشیده میشدند یا به کسانی بدل میشدند که در مراسم نوارهای تزیینی قیچی میکردند و با دیگران دست میدادند شاه حوادث نظام های سلطنتی قرن بیستم را از سر گذراند و تصمیم گرفت هم سلطنت کند و هم حکومت شاه در سال 1341 انقلاب سفید خود را نه صرفا برای انباشت قدرت آغاز کرد که برنامه ای بلند پروازانه برای اصلاحات اجتماعی و اقتصادی داشت با هدف تبدیل ایران از سلطنتی نیمه ارباب رعیتی به یک قدرت مدرن صنعتی در نتیجه کشاورزان روستایی رعیتها از قید ارباب ها آزاد شدند جنگلها و مراتع و آبراه ها ملی شد زنان از حقوق اجتماعی و برابر و سیاسی برخوردار شدند چهار سال بعد زمانی که شاه مراسم تاج گذاری به تاخیر افتاده اش را برگزار کرد درصد رشد اقتصادی ایران از ایالات متحده آمریکا و بریتانیای کبیر و فرانسه پیشی گرفته بود. منتقدانی که زمانی شاه ایران را خوش گذرانی بی تجربه معرفی و رد میکردند حال موفقیتها و فراست او را ستایش میکردند روزنامه انگلیسی دیلی میل نوشت ما خوش وقتیم که در روز تاج گذاری پادشاه ایران به او ادای احترام کنیم در 26 سال سلطنتش شاه حتی یک بار کشورش را درگیر جنگ نساخت او راه غلبه بر گرسنگی و فقر و فلاکت و بیماری را نشان داده است با روشهایی که کشورهای دیگر میتوانند از آن درس بگیرند. پهلوی در آنجا متوقف نشد در اوایل دهه هفتاد میلادی از تنشهای جنگ سرد برای تسلط بر خلیج فارس بهره برداری کرد و سپس کودتای قرن را با طراحی و اجرای شوک نفتی دسامبر1973 / دی ماه1352عملی ساخت دو برابر شدن بهای نفت در یک شب عظیم ترین انتقال دارایی در بین کشورهای مستقل در تاریخ مضبوط را موجب شد. رهبر دومین صادر کننده نفت در جهان غرق در میلیاردها دلار دارایی ایران منابعش را سخاوتمندانه خرج صنعت آموزش بهداشت رفاه هنر نیروهای مسلح میکرد. در مرکز برنامه اصلاحی او تعهدی استوار به آموزش وجود داشت.... #جاویدشاه #رضاشاه_دوم #پهلوی'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CyHRjgzJs5-d",
        "outputId": "676b9ab4-a6a4-45f3-ac9e-00e29db6c454"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting perke\n",
            "  Downloading perke-0.4.4-py3-none-any.whl (25 kB)\n",
            "Collecting hazm (from perke)\n",
            "  Downloading hazm-0.10.0-py3-none-any.whl (892 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m892.6/892.6 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from perke) (3.8.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from perke) (3.2.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from perke) (1.11.4)\n",
            "Collecting typer==0.5.0 (from perke)\n",
            "  Downloading typer-0.5.0-py3-none-any.whl (28 kB)\n",
            "Collecting rich-click==1.5.2 (from perke)\n",
            "  Downloading rich_click-1.5.2-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (from perke) (4.7.3)\n",
            "Requirement already satisfied: click>=7 in /usr/local/lib/python3.10/dist-packages (from rich-click==1.5.2->perke) (8.1.7)\n",
            "Requirement already satisfied: rich>=10.7.0 in /usr/local/lib/python3.10/dist-packages (from rich-click==1.5.2->perke) (13.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown->perke) (3.13.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown->perke) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown->perke) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown->perke) (4.66.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown->perke) (4.12.3)\n",
            "Collecting fasttext-wheel<0.10.0,>=0.9.2 (from hazm->perke)\n",
            "  Downloading fasttext_wheel-0.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flashtext<3.0,>=2.7 (from hazm->perke)\n",
            "  Downloading flashtext-2.7.tar.gz (14 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: gensim<5.0.0,>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from hazm->perke) (4.3.2)\n",
            "Collecting numpy==1.24.3 (from hazm->perke)\n",
            "  Downloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-crfsuite<0.10.0,>=0.9.9 (from hazm->perke)\n",
            "  Downloading python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn<2.0.0,>=1.2.2 in /usr/local/lib/python3.10/dist-packages (from hazm->perke) (1.2.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->perke) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->perke) (2023.12.25)\n",
            "Collecting pybind11>=2.2 (from fasttext-wheel<0.10.0,>=0.9.2->hazm->perke)\n",
            "  Downloading pybind11-2.11.1-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.7/227.7 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext-wheel<0.10.0,>=0.9.2->hazm->perke) (67.7.2)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim<5.0.0,>=4.3.1->hazm->perke) (6.4.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.7.0->rich-click==1.5.2->perke) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.7.0->rich-click==1.5.2->perke) (2.16.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0.0,>=1.2.2->hazm->perke) (3.2.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown->perke) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->perke) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->perke) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->perke) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->perke) (2024.2.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->perke) (1.7.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.7.0->rich-click==1.5.2->perke) (0.1.2)\n",
            "Building wheels for collected packages: flashtext\n",
            "  Building wheel for flashtext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flashtext: filename=flashtext-2.7-py2.py3-none-any.whl size=9296 sha256=bbd12a02faef721f428f4dc433c544644cdbf484f3bbbafa6781cacd53196b64\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/be/39/c37ad168eb2ff644c9685f52554440372129450f0b8ed203dd\n",
            "Successfully built flashtext\n",
            "Installing collected packages: python-crfsuite, flashtext, typer, pybind11, numpy, fasttext-wheel, rich-click, hazm, perke\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.9.0\n",
            "    Uninstalling typer-0.9.0:\n",
            "      Successfully uninstalled typer-0.9.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchvision 0.16.0+cu121 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed fasttext-wheel-0.9.2 flashtext-2.7 hazm-0.10.0 numpy-1.24.3 perke-0.4.4 pybind11-2.11.1 python-crfsuite-0.9.10 rich-click-1.5.2 typer-0.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Q3JK4NVUC2t5QT63aDiVrCRBV225E_B3\n",
            "To: /usr/local/lib/python3.10/dist-packages/perke/resources/pos_tagger.model\n",
            "100% 19.2M/19.2M [00:00<00:00, 43.5MB/s]\n",
            "1. \tدست\n",
            "2. \tفرانسه پیشی\n",
            "3. \tآخوندها\n",
            "4. \tزبان انگلیسی\n",
            "5. \tتخت طاووس\n",
            "6. \tحکومت شاه\n",
            "7. \tآخوندی\n",
            "8. \tبیماری\n",
            "9. \tفلاکت\n",
            "10. \tفقر\n"
          ]
        }
      ],
      "source": [
        "!pip install perke\n",
        "!python -m perke download\n",
        "import numpy as np\n",
        "def dummy_npwarn_decorator_factory():\n",
        "  def npwarn_decorator(x):\n",
        "    return x\n",
        "  return npwarn_decorator\n",
        "np._no_nep50_warning = getattr(np, '_no_nep50_warning', dummy_npwarn_decorator_factory)\n",
        "from perke.unsupervised.graph_based import TopicRank\n",
        "\n",
        "tags, without_tag=pure_caption(caption)\n",
        "\n",
        "# Merging modified caption text and STT result if existed:\n",
        "if useful_content:\n",
        "   goal_text=without_tag+corrected_text\n",
        "else:\n",
        "   goal_text=without_tag\n",
        "\n",
        "# Goal Grammars:\n",
        "valid_pos_tags = {'NOUN', 'NUM','NOUN,EZ','ADJ','NUM,EZ'}\n",
        "\n",
        "# Create a TopicRank extractor:\n",
        "extractor = TopicRank(valid_pos_tags=valid_pos_tags)\n",
        "\n",
        "# Finding candidates:\n",
        "extractor.load_text(input=goal_text, word_normalization_method=None)\n",
        "extractor.select_candidates()\n",
        "extractor.weight_candidates(threshold=0.5, metric='jaccard', linkage_method='average')\n",
        "\n",
        "# Finding Keyword with Topic Rank Method:\n",
        "keyphrases = extractor.get_n_best(n=20)\n",
        "score=[20,19,18,17,16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1]\n",
        "keywords=[]\n",
        "for i,(keyphrase,weight) in enumerate(keyphrases):\n",
        "  keywords.append(keyphrase)\n",
        "\n",
        "# Finding similarity between output keywords and hashtags in caption and Double score them:\n",
        "similarity=list(set(keywords).intersection(tags))\n",
        "for i in range(0,len(similarity)):\n",
        "  index=keywords.index(similarity[i])\n",
        "  score[index]=score[index]*2\n",
        "\n",
        "dict_score = {score[i]:keywords[i] for i in range(len(keywords))}\n",
        "sorted_dict = dict(sorted(dict_score.items()))\n",
        "for i in range(0,10):\n",
        "    print(f'{i+1}. \\t{sorted_dict[20-i]}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "BBlQm_KfZGLV",
        "iAw__QYnY9xl",
        "wZ6Zqm_3zOFb",
        "BWGw04hmqkxu",
        "XosrpYnDqhGJ",
        "wOXehbZWPa_u",
        "OWJRFVBRy7g8",
        "DOLBh2s3BGXq",
        "q6XtGalyChvj",
        "Zqq1jvvtAq2r"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
